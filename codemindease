'use client';

import { useState, useEffect, useRef } from 'react';
import { useTranslation } from 'react-i18next';
import { useAuth } from '../contexts/AuthContext';
import { toast } from 'react-toastify';
import SockJS from 'sockjs-client';
import { Client } from '@stomp/stompjs';
import '../styles/Chat.css';
import { apiGet } from '../lib/api';
import useVoiceRecorder from '../hooks/useVoiceRecorder';
import useTextToSpeech from '../hooks/useTextToSpeech';
import VoicePlayer from '../components/VoicePlayer';
import { mapI18nToSpeechLang } from '../utils/speechUtils';

const API_BASE_URL = (import.meta.env.VITE_API_BASE_URL || 'http://localhost:8080').replace(
  /\/$/,
  ''
);

const Chat = () => {
  const { t, i18n } = useTranslation();
  const { token, currentUser } = useAuth();
  const [messages, setMessages] = useState([]);
  const [inputValue, setInputValue] = useState('');
  const [isConnected, setIsConnected] = useState(false);
  const messagesEndRef = useRef(null);
  const [isTyping, setIsTyping] = useState(false);
  const [historyPage, setHistoryPage] = useState(null);
  const [hasMoreHistory, setHasMoreHistory] = useState(true);
  const [loadingHistory, setLoadingHistory] = useState(false);
  const [initialLoadComplete, setInitialLoadComplete] = useState(false);

  const [voiceInputEnabled] = useState(() => {
    const saved = localStorage.getItem('voiceSettings');
    return saved ? JSON.parse(saved).voiceInputEnabled !== false : true;
  });
  const [voiceOutputEnabled] = useState(() => {
    const saved = localStorage.getItem('voiceSettings');
    return saved ? JSON.parse(saved).voiceOutputEnabled === true : false;
  });
  const [_voiceStatusText, setVoiceStatusText] = useState(''); // Used in voice conversation mode
  const [isVoiceTranscribed, setIsVoiceTranscribed] = useState(false);
  const [currentPlayingMessageId, setCurrentPlayingMessageId] = useState(null);
  const [messageQueue, setMessageQueue] = useState([]);
  const [isVoiceConversationActive, setIsVoiceConversationActive] = useState(false);
  const inputRef = useRef(null);
  const userCancelledRecordingRef = useRef(false);
  const manuallyStoppedTTSRef = useRef(false);
  const isStartingRecordingRef = useRef(false);
  const retryCountRef = useRef(0);
  const MAX_RETRIES = 3;
  const ttsStateRef = useRef({ isPlaying: false, stopSpeech: null });

  const stompClientRef = useRef(null);
  const isConnectingRef = useRef(false);
  const isIntentionallyDisconnectingRef = useRef(false);
  const processedMessageIds = useRef(new Map());
  const messagesContainerRef = useRef(null);
  const preventAutoScrollRef = useRef(false);
  const prevScrollHeightRef = useRef(null);

  // Shared function to send messages to the server
  const sendMessageToServer = async (messageText) => {
    if (!messageText.trim()) return false;
    if (!stompClientRef.current || !isConnected) {
      toast.error('Not connected to chat. Please refresh the page.');
      return false;
    }

    setIsTyping(true);

    try {
      const response = await fetch(`${API_BASE_URL}/api/chat/send`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${token}`,
        },
        body: JSON.stringify({
          message: messageText,
        }),
      });

      const result = await response.json();

      if (!response.ok) {
        throw new Error(result.message || 'Failed to send message');
      }

      return true;
    } catch (error) {
      console.error('Error sending message:', error);
      toast.error('Failed to send message: ' + error.message);
      return false;
    } finally {
      setTimeout(() => {
        setIsTyping(false);
      }, 1500);
    }
  };

  const sendVoiceMessage = async (text) => {
    const success = await sendMessageToServer(text);
    if (success) {
      setInputValue('');
      setIsVoiceTranscribed(false);
    }
  };

  // Helper function to interrupt TTS when user starts speaking
  const interruptTTS = () => {
    const { isPlaying, stopSpeech } = ttsStateRef.current;
    if (isVoiceConversationActive && (isPlaying || window.speechSynthesis?.speaking)) {
      if (stopSpeech) stopSpeech();
      setCurrentPlayingMessageId(null);
      setMessageQueue([]);
      // Force cancel any pending TTS synchronously
      if (window.speechSynthesis) {
        window.speechSynthesis.cancel();
      }
    }
  };

  const {
    startRecording,
    cancelRecording,
    isRecording,
    isSupported: isVoiceSupported,
    isTranscribing,
  } = useVoiceRecorder({
    language: mapI18nToSpeechLang(i18n.language),
    onStart: () => {
      // Recording has actually started - reset the flag
      isStartingRecordingRef.current = false;
      // User started speaking - interrupt TTS immediately (user has priority)
      interruptTTS();
    },
    onInterimResult: () => {
      // User is speaking - interrupt TTS as soon as we detect speech (even interim)
      // This is more responsive than waiting for onStart
      interruptTTS();
    },
    onTranscriptionComplete: (text) => {
      setInputValue(text);
      setIsVoiceTranscribed(true);
      setVoiceStatusText('');
      retryCountRef.current = 0; // Reset retry counter on successful transcription

      if (isVoiceConversationActive) {
        sendVoiceMessage(text);
        // Immediately restart listening after sending message
        setTimeout(() => {
          if (
            !isRecording &&
            !isTranscribing &&
            isVoiceConversationActive &&
            !isStartingRecordingRef.current
          ) {
            isStartingRecordingRef.current = true;
            startRecording();
            setVoiceStatusText(t('chat.listening'));
          }
        }, 100);
      } else {
        if (inputRef.current) {
          inputRef.current.focus();
        }
      }
    },
    onError: (err) => {
      // Don't show toast for 'aborted' errors - they're expected when canceling
      // Also don't show for 'no-speech' errors - they're normal
      if (err && !err.includes('cancelled') && !err.includes('no-speech')) {
        toast.error(err);
      }
      setVoiceStatusText('');
      isStartingRecordingRef.current = false;

      // Restart listening after error in conversation mode (except for aborted/cancelled)
      if (isVoiceConversationActive && err && !err.includes('cancelled')) {
        if (retryCountRef.current >= MAX_RETRIES) {
          toast.error(t('chat.voiceRecordingFailed'));
          setIsVoiceConversationActive(false);
          retryCountRef.current = 0;
          return;
        }
        retryCountRef.current += 1;
        setTimeout(() => {
          if (!isRecording && !isTranscribing && !isStartingRecordingRef.current) {
            isStartingRecordingRef.current = true;
            startRecording();
            setVoiceStatusText(t('chat.listening'));
          }
        }, 500);
      }
    },
    silenceTimeoutMs: 5000,
    maxDurationMs: 60000,
  });

  const {
    speak,
    stop: stopSpeech,
    pause: pauseSpeech,
    resume: resumeSpeech,
    isPlaying,
    isPaused,
    isSupported: isTTSSupported,
  } = useTextToSpeech({
    language: mapI18nToSpeechLang(i18n.language),
    defaultRate: (() => {
      const saved = localStorage.getItem('voiceSettings');
      return saved ? JSON.parse(saved).speechRate || 1.0 : 1.0;
    })(),
    defaultVolume: (() => {
      const saved = localStorage.getItem('voiceSettings');
      return saved ? JSON.parse(saved).volume || 1.0 : 1.0;
    })(),
    onComplete: () => {
      setCurrentPlayingMessageId(null);

      // Play next message in queue if available
      if (messageQueue.length > 0) {
        const nextMessage = messageQueue[0];
        setMessageQueue((prev) => prev.slice(1));
        setCurrentPlayingMessageId(nextMessage.id);
        speak(nextMessage.content);
      }
      // Note: Listening is handled continuously, no need to restart here
    },
    onError: (err) => {
      if (err?.error !== 'interrupted' && err?.error !== 'canceled') {
        console.error('TTS error:', err);
      }
      setCurrentPlayingMessageId(null);

      if (messageQueue.lengt